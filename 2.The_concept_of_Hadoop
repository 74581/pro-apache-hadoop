2.Hadoop中的概念
    普通计算机经常满足不了应用程序的计算资源需求，很多企业的业务应用程序已不适合在单台廉价的计算机上运行
    一个简单昂贵的方案是购买具有多CPU的高端服务器，这通常需要巨额资金，预算是个大问题
    一个替代方案是搭建一个高可用的集群，很多高可用的集群都是企业专有且价格昂贵
    一个更经济实惠的解决方案是云计算：
        面对大数据量的处理需求，常用方法是把它们分割成互不依赖的小份数据分布处理
        即单指令多数据流（single-instruation, multiple-data, SIMD）的数据计算模式
        Hadoop为这样的云计算需求提供了一套开源的计算框架和一套分布式文件系统
2.1Hadoop简介
    以谷歌2004年发表的关于MapReduce的论文为基础开发，始于2005年，是开源网页搜索引擎Nutch项目下的一个子项目
    后从Nutch项目分离出来，成为了Apache基金会的顶级项目
    Hadoop是一个基于Java的MapReduce框架，也加入了对非Java的支持，以下是Hadoop的改进及其子项目：
        Hadoop Streaming：
            任何命令行脚本都可通过Streaming调用MapReduce框架，UNIX、Python程序员可用来开发临时任务
        Hadoop Hive：
            开发一个MapReduce程序需要大量编码工作，易出错且难以测试
            用户需要类似SQL的语言，可以关注于业务问题而不必关心类似SQL命令功能的底层实现
            Apache Hive可以把海量数据集放入数据仓库，用户可以编写类似SQL语句的Hive查询语句来查找数据
            Hive引擎把Hive查询语句透明地转换为底层MapReduce任务来执行
            高级用户可以使用Java语言来编写用户自定义函数（UDF），Hive也支持标准地ODBC、JDBC数据库驱动
            或开发商用智能（Business Intelligence，BI）分析程序处理分析存放在Hadoop中的数据
        Hadoop Pig：
            与使用Hive的目的一样，但Hive是类SQL语言，属于陈述性语言；Pig是一种过程性语言，适合数据管道应用场景
            Pig适合开发抽取、加载和传输（ETL）类型的程序，对数据处理管道程序的程序员有用（如SAS程序员）
        Hadoop HBase：
            以上项目都是批处理程序，现在有需求是在Hadoop中实时查询数据，这样的场景用例就是开发HBase平台的目的
            如想查看Facebook一个朋友的用户资料，需要立即得到结果，而不是进经过长时间的批处理任务执行
    Hadoop系统最早是作为用于海量文本数据的MapReduce引擎而启动的项目，后发展成通用的大数据处理模型，支持标准的企业级应用
    
    以前Hadoop系统只能在用户提交任务后以先进先出（FIFO）的模式在集群上执行任务
    运行耗时、重要性低的任务占用大量的集群资源，而运行时间短、重要性高的任务无法运行
    因此Hadoop中出现了更复杂的任务调度器，如公平调度器（Fair Scheduler）和计算能力调度器（Capacity Scheduler）
    Hadoop 1.x系列（版本号小于0.23）中，系统本身设计的决策导致了集群在可扩展性方面的限制
    如Yahoo发现当Hadoop系统集群的计算节点数量叨叨数千台量级的时候，集群会存在可扩展性问题
    Hadoop的工程师们重新评估了Hadoop系统原型设计中的一些基础假设，核心架构被重新设计，Hadoop 2.x（版本号大于0.23）诞生

2.2MapReduce编程模型简介
    该模型可利用由大量商用服务器构成的大规模集群来处理千兆级数据量的问题
    该模型有连个彼此独立的步骤，均可以配置并需要用户在程序中自定义：
        Map：数据初始读取和转换步骤，每个独立输入数据记录都进行并行处理
        Reduce：数据整合或加和步骤，相关联的所有数据记录要放在一个计算节点来处理
    核心思路：
        将数据在逻辑上分割成多个数据块，每个逻辑数据块被Map任务单独地处理
        处理后所得结果被划分到不同地数据集，且完成排序，每个经过排序的数据集传输到Reduce任务进行处理
    
    一个Map任务可在集群任何计算节点上运行，多个Map任务可并行地运行在集群上
    Map任务的主要作用就是把输入的数据记录（input records）转换为一个个键值对
    所有Map任务的输出数据都会进行分区，并且将每个分区的数据排序
    每个分区对应一个Reduce任务，分区内已排好序的键值对会由一个Reduce任务处理，有多个Reduce任务在集群上并行运行
    一般情况下，开发仅需关注以下四个类：
        一个类用来读取输入的数据记录，并将每条数据记录转换成一个键值对
        一个Mapper类
        一个Reduce类
        一个类是将Reduce方法输出的键值对转换成输出记录进行输出
    
    以计数程序（the word-count application）讲解MapReduce的编程思想：
        假设有海量文本文档，可以做很多分析（如信息提取，给予文本内容的文档聚类，基于语义的文档分类）
        大多数文本分析最开始要做的就是统计文档语料库中每个单词的数量（文档集合通常被称为一个语料库，corpus）
        另一用途是计算一个词/文档对应的“词频/逆向文件频率”（TF/IDF）
        简单假定文档中的每个词是使用空格分隔，一个解决方案是：
            1.维护一个哈希表（hashmap），键为文本中的每个词，值是词的个数
            2.把每篇文档加载到内存
            3.把文档分隔成一个个词
            4.对每个词更新计数
            5.所有文档处理完即得所有单词的计数

        使用MapReduce实现步骤：
            1.一个多台服务器组成的集群，假设该集群的计算节点为50
            2.每台服务器上运行大量的Map处理，假设多少个文件被处理就有多少个Map处理
                （假设不严谨，如压缩模式下的文件或其他格式的序列文件时该假设不成立）假设有一千万个文件，有一千万个Map处理
                在给定的时间内，假设有多少个CPU核，就有多少个Map处理可以同时运行，集群服务器是8核CPU，8个Mapper同时运行
                每个服务器负责运行20万个Map处理，每个计算节点同时运行8个Mapper，共25000次迭代
            3.每个Mapper处理一个文件，抽取文件中的单词，并输出如下键值对：<{WORD}, 1>，输出如下
                <the,1>
                <the,1>
                <test,1>
            4.假设只有一个Reducer，即默认的设定，实际场景常需要改变
            5.Reducer接受如下键值对：<{WORD},[1,...1]>
                键为任意一个Mapper输出的单词（<WORD>），值为任意一个Mapper输出与键对应的一组值（[1,...1]），示例如下：
                <the,[1,1,1,...,1]>
                <test,[1,1]>
            6.Reducer每处理一个相同的单词，就简单地将该单词地计数加1，最终得到总数按如下格式输出：<{WORD},{单词总数}>，如下：
                <the,10001001>
                <test,2>
        从一个键对应一个值变换成在Reduce阶段接受的一个键对应一组值，该过程称为排序/混洗（sort/shuffle）阶段
        由Mapper任务输出的所有键值对在Reducer任务中都按键排序了，若配置多个Reducer，每个Reducer将会处理键值对集合中的某个子集
        在Reducer处理前按键排序，确保相同键对应的值会由同一个Reducer接受并处理

            在Reducer阶段，Reduce任务执行前，并不真正为每个键创建一个对应的值列表，否则会轻易占满运行Reducer的Java虚拟机（JVM）内存
            在sort/shuffle阶段，键the对应的所有的值1会被一起传送到相应的运行Reducer的计算节点的本地文件系统
            当Reducer开始处理键the时，对应的值1会通过Java迭代接口流式地读入

        Hadoop系统从系统结构设计上就确保了大多数Mapper都从本地磁盘读取文件
        尽管HDFS的总体设计使得文件对网络传输交换是敏感的，以此确保计算被调度到文件所在的位置来本地执行
        但从MapReduce系统来看这是一个统一的文件系统，即著名的Hadoop分布式文件系统（HDFS）

2.3Hadoop系统的组成
    宏观上说，Hadoop 1.x系统由以下几个守护进程：
        名称节点（NameNode）：
            维护存储在HDFS上的所有文件的元数据信息，包括组成文件的数据块信息，及这些数据块在数据节点上的位置
            这个组件正是使用Hadoop 1.x搭建大型计算集群系统的瓶颈所在
        辅助名称节点（Secondary NameNode）：
            这不是名称节点的热备份，其命名不恰当，它为名称节点组件执行一些内务处理功能（housekeeping functions）
        数据节点（DataNode）：
            把真正的数据块存放在本地硬盘上，组成保存在HDFS上的每个文件
        作业跟踪器（JobTracker）：
            主要组件之一，负责一个任务的整个执行过程，具体功能包括：
                调度各个子任务（Mapper任务和Reducer任务各自的子任务）到各自的计算节点运行
                时刻监督任务运行和计算节点的健康状况
                对失败的子任务重新调度执行
            也是使用Hadoop 1.x搭建大型计算集群系统的瓶颈所在
        任务跟踪器（TaskTracker）：
            运行在各个数据节点上，用来启动和管理各个Map/Reduce任务，与作业跟踪器进行通信
    
    Hadoop 1.x集群有两种类型的节点：主节点（master nodes）和从节点（slave nodes）
    主节点负责执行如下守护进程：
        名称节点进程
        辅助名称节点进程
        作业跟踪器进程
    从节点分布在整个集群上并执行如下守护进程：
        数据节点进程
        任务跟踪进程
    
    整个集群上，每种主节点守护进程只有一个运行实例，但其数据节点进程和任务跟踪器进程有多个运行实例
    规模较小或用于开发/测试的集群，三个主节点进程在一台服务器上；生产环境系统或规模较大的集群，三个主节点进程分别运行在不同的服务器上较好

    2.3.1Hadoop分布式文件系统
        即HDFS，用于支持大数据处理程序要处理的大文件，有一次写、多次读的特点，由以下几个守护进程协调运行来提供服务：
            名称节点进程
            辅助名称节点进程
            数据节点进程
        HDFS系统也是主从架构，运行名称节点进程的服务器为主节点，运行数据节点进程的服务器为从节点
        一般集群每个从节点都会运行一个数据节点进程，管理着挂载到这个数据节点上的存储设备
        HDFS系统提供一个统一的文件系统命名空间，用户像使用文件系统一样来存取集群节点上的数据
        名称节点进程负责管理存储在集群上的文件的元数据

        1.Hadoop文件的本质是块存储
            集群中文件的物理存储方式：每个文件被分隔为多个数据块，典型大小为64MB，也可配置为32MB或128MB
            文件块大小按照文件大小配置，若文件大小不是文件块大小的整数倍，空间不会浪费很多，只是最后一个文件块未被完全占满
            每个数据块存储在数据节点上，为防止节点故障，数据块有备份，备份默认配置为3
            具备机架感知功能的Hadoop系统把文件的一个数据块存放在本地机架上的一台计算节点上
            （假设Hadoop客户端运行在本地机架中的一台数据节点上，否则会随机选择一个机架）
            第二个备份存放在另外一个远程机架上的计算节点中，第三个备份存放在第二个数据块备份机架上的另一台计算节点中
            Hadoop系统借助一个单独配置的网络拓扑文件实现机架感知功能，该文件配置了机架到计算节点的域名系统（DNS）名称之间的映射
            该文件的路径配置在Hadoop配置文件中
                许多Hadoop系统会把文件备份因子降为2，如运行在EMC公司的Isilon硬件上的Hadoop系统
                原因是这套硬件系统使用了RAID5的技术，该技术本身内置了数据的冗余备份，从而可降低Hadoop系统的文件备份因子
                降低文件备份因子的一个好处就是提高系统的I/O性能（少写一个备份）

            为什么不把三个文件数据块备份分别存放在不同的机架上？这样可以增加数据冗余度，抵御机架故障的能力更强，还可增加机架的数据吞吐量
            但是，机架故障的概率远低于计算节点故障的概率，而把数据块备份到不同机架可导致Hadoop系统写性能大幅下降
            所以，折中方案就是把两个数据块备份存放在同一个远程机架上的不同计算节点中，以换取Hadoop系统写性能的提高

        2.文件元数据和名称节点
            当客户端向HDFS请求读取或存储一个文件时，需要知道要访问的数据节点是哪一个，知道之后可直接访问那个数据节点
            文件的元数据信息由名称节点维护，HDFS系统提供一个统一的文件系统命名空间，用户像使用文件系统一样存取集群节点上的数据
            HDFS把存储在目录的文件按一定的层级展示，目录是可嵌套的，所有文件和目录的元数据信息都由名称节点管理

            名称节点管理所有的文件操作，包括文件/目录的打开、关闭、重命名、移动等，数据节点负责存储实际文件数据
            当客户点请求或发送文件数据，其物理上不经过名称节点传输，客户端仅从名称节点获取文件元数据，后根据信息直接从数据节点获取数据块
            名称节点存储的一些元数据：
                文件/目录名称及相对于其父目录的位置
                文件和目录的所有权及权限
                各个数据块的文件名，所有数据块以文件形式存放在数据节点的本地文件系统的目录中，目录可被Hadoop系统管理员配置

            注意，名称节点不存储每个数据块的位置（数据节点的身份信息），数据节点的身份信息（DataNode identity）在集群启动时从每个数据节点获取
            名称节点维护的信息是，HDFS上的文件由哪些数据块（数据节点上每个数据块的文件名）组成

            元数据存储在名称节点的本地磁盘上，但为了快速访问，在集群操作时会把这些元信息加载到内存，同时也成为一个瓶颈，催生了Hadoop 2.x系统
            每个元数据信息大约占用200字节的RAM，假设一个1GB大小的文件，数据块大小为64MB，需要16X3（包括备份数量）=48个数据块的存储量
            假设由1000个文件，每个大小1MB，需要1000X3=3000个数据块的存储量（每个文件占用数据块1MB存储空间，多个文件不能存储在同一数据块中）
            如此元数据的数据量会大幅增长，导致名称节点更大的内存占用，这也解释了为什么Hadoop系统更适合存储大文件，不适合存储大量小文件

            名称节点服务器存放元数据的文件为fsimage
            Hadoop系统运行期间任何涉及元数据修改的操作都保存在内存中，并被持久存储到另一个edits文件
            辅助名称节点会周期性地把edits文件中的信息合并到fsimage文件
            保存在HDFS的实际文件数据并不会存放在fsimage和edits文件，实际数据存放在运行着数据节点守护进程的从节点的数据块中
            但如果名称节点保存的元数据丢失，会导致整个集群不可用
            数据节点守护进程周期性的发送心跳信息给名称节点，使得名称节点可以感知所有数据节点的健康状况，从而客户端的请求不会被发送到故障数据节点
