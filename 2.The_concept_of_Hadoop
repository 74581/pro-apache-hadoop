2.Hadoop中的概念
    普通计算机经常满足不了应用程序的计算资源需求，很多企业的业务应用程序已不适合在单台廉价的计算机上运行
    一个简单昂贵的方案是购买具有多CPU的高端服务器，这通常需要巨额资金，预算是个大问题
    一个替代方案是搭建一个高可用的集群，很多高可用的集群都是企业专有且价格昂贵
    一个更经济实惠的解决方案是云计算：
        面对大数据量的处理需求，常用方法是把它们分割成互不依赖的小份数据分布处理
        即单指令多数据流（single-instruation, multiple-data, SIMD）的数据计算模式
        Hadoop为这样的云计算需求提供了一套开源的计算框架和一套分布式文件系统
2.1Hadoop简介
    以谷歌2004年发表的关于MapReduce的论文为基础开发，始于2005年，是开源网页搜索引擎Nutch项目下的一个子项目
    后从Nutch项目分离出来，成为了Apache基金会的顶级项目
    Hadoop是一个基于Java的MapReduce框架，也加入了对非Java的支持，以下是Hadoop的改进及其子项目：
        Hadoop Streaming：
            任何命令行脚本都可通过Streaming调用MapReduce框架，UNIX、Python程序员可用来开发临时任务
        Hadoop Hive：
            开发一个MapReduce程序需要大量编码工作，易出错且难以测试
            用户需要类似SQL的语言，可以关注于业务问题而不必关心类似SQL命令功能的底层实现
            Apache Hive可以把海量数据集放入数据仓库，用户可以编写类似SQL语句的Hive查询语句来查找数据
            Hive引擎把Hive查询语句透明地转换为底层MapReduce任务来执行
            高级用户可以使用Java语言来编写用户自定义函数（UDF），Hive也支持标准地ODBC、JDBC数据库驱动
            或开发商用智能（Business Intelligence，BI）分析程序处理分析存放在Hadoop中的数据
        Hadoop Pig：
            与使用Hive的目的一样，但Hive是类SQL语言，属于陈述性语言；Pig是一种过程性语言，适合数据管道应用场景
            Pig适合开发抽取、加载和传输（ETL）类型的程序，对数据处理管道程序的程序员有用（如SAS程序员）
        Hadoop HBase：
            以上项目都是批处理程序，现在有需求是在Hadoop中实时查询数据，这样的场景用例就是开发HBase平台的目的
            如想查看Facebook一个朋友的用户资料，需要立即得到结果，而不是进经过长时间的批处理任务执行
    Hadoop系统最早是作为用于海量文本数据的MapReduce引擎而启动的项目，后发展成通用的大数据处理模型，支持标准的企业级应用
    
    以前Hadoop系统只能在用户提交任务后以先进先出（FIFO）的模式在集群上执行任务
    运行耗时、重要性低的任务占用大量的集群资源，而运行时间短、重要性高的任务无法运行
    因此Hadoop中出现了更复杂的任务调度器，如公平调度器（Fair Scheduler）和计算能力调度器（Capacity Scheduler）
    Hadoop 1.x系列（版本号小于0.23）中，系统本身设计的决策导致了集群在可扩展性方面的限制
    如Yahoo发现当Hadoop系统集群的计算节点数量叨叨数千台量级的时候，集群会存在可扩展性问题
    Hadoop的工程师们重新评估了Hadoop系统原型设计中的一些基础假设，核心架构被重新设计，Hadoop 2.x（版本号大于0.23）诞生

2.2MapReduce编程模型简介
    该模型可利用由大量商用服务器构成的大规模集群来处理千兆级数据量的问题
    该模型有连个彼此独立的步骤，均可以配置并需要用户在程序中自定义：
        Map：数据初始读取和转换步骤，每个独立输入数据记录都进行并行处理
        Reduce：数据整合或加和步骤，相关联的所有数据记录要放在一个计算节点来处理
    核心思路：
        将数据在逻辑上分割成多个数据块，每个逻辑数据块被Map任务单独地处理
        处理后所得结果被划分到不同地数据集，且完成排序，每个经过排序的数据集传输到Reduce任务进行处理
    
    一个Map任务可在集群任何计算节点上运行，多个Map任务可并行地运行在集群上
    Map任务的主要作用就是把输入的数据记录（input records）转换为一个个键值对
    所有Map任务的输出数据都会进行分区，并且将每个分区的数据排序
    每个分区对应一个Reduce任务，分区内已排好序的键值对会由一个Reduce任务处理，有多个Reduce任务在集群上并行运行
    一般情况下，开发仅需关注以下四个类：
        一个类用来读取输入的数据记录，并将每条数据记录转换成一个键值对
        一个Mapper类
        一个Reduce类
        一个类是将Reduce方法输出的键值对转换成输出记录进行输出
    
    以计数程序（the word-count application）讲解MapReduce的编程思想：
        假设有海量文本文档，可以做很多分析（如信息提取，给予文本内容的文档聚类，基于语义的文档分类）
        大多数文本分析最开始要做的就是统计文档语料库中每个单词的数量（文档集合通常被称为一个语料库，corpus）
        另一用途是计算一个词/文档对应的“词频/逆向文件频率”（TF/IDF）
        简单假定文档中的每个词是使用空格分隔，一个解决方案是：
            1.维护一个哈希表（hashmap），键为文本中的每个词，值是词的个数
            2.把每篇文档加载到内存
            3.把文档分隔成一个个词
            4.对每个词更新计数
            5.所有文档处理完即得所有单词的计数

        使用MapReduce实现步骤：
            1.一个多台服务器组成的集群，假设该集群的计算节点为50
            2.每台服务器上运行大量的Map处理，假设多少个文件被处理就有多少个Map处理
                （假设不严谨，如压缩模式下的文件或其他格式的序列文件时该假设不成立）假设有一千万个文件，有一千万个Map处理
                在给定的时间内，假设有多少个CPU核，就有多少个Map处理可以同时运行，集群服务器是8核CPU，8个Mapper同时运行
                每个服务器负责运行20万个Map处理，每个计算节点同时运行8个Mapper，共25000次迭代
            3.每个Mapper处理一个文件，抽取文件中的单词，并输出如下键值对：<{WORD}, 1>，输出如下
                <the,1>
                <the,1>
                <test,1>
            4.假设只有一个Reducer，即默认的设定，实际场景常需要改变
            5.Reducer接受如下键值对：<{WORD},[1,...1]>
                键为任意一个Mapper输出的单词（<WORD>），值为任意一个Mapper输出与键对应的一组值（[1,...1]），示例如下：
                <the,[1,1,1,...,1]>
                <test,[1,1]>
            6.Reducer每处理一个相同的单词，就简单地将该单词地计数加1，最终得到总数按如下格式输出：<{WORD},{单词总数}>，如下：
                <the,10001001>
                <test,2>
        从一个键对应一个值变换成在Reduce阶段接受的一个键对应一组值，该过程称为排序/混洗（sort/shuffle）阶段
        由Mapper任务输出的所有键值对在Reducer任务中都按键排序了，若配置多个Reducer，每个Reducer将会处理键值对集合中的某个子集
        在Reducer处理前按键排序，确保相同键对应的值会由同一个Reducer接受并处理

            在Reducer阶段，Reduce任务执行前，并不真正为每个键创建一个对应的值列表，否则会轻易占满运行Reducer的Java虚拟机（JVM）内存
            在sort/shuffle阶段，键the对应的所有的值1会被一起传送到相应的运行Reducer的计算节点的本地文件系统
            当Reducer开始处理键the时，对应的值1会通过Java迭代接口流式地读入

        Hadoop系统从系统结构设计上就确保了大多数Mapper都从本地磁盘读取文件
        尽管HDFS的总体设计使得文件对网络传输交换是敏感的，以此确保计算被调度到文件所在的位置来本地执行
        但从MapReduce系统来看这是一个统一的文件系统，即著名的Hadoop分布式文件系统（HDFS）

2.3Hadoop系统的组成
    宏观上说，Hadoop 1.x系统由以下几个守护进程：
        名称节点（NameNode）：
            维护存储在HDFS上的所有文件的元数据信息，包括组成文件的数据块信息，及这些数据块在数据节点上的位置
            这个组件正是使用Hadoop 1.x搭建大型计算集群系统的瓶颈所在
        辅助名称节点（Secondary NameNode）：
            这不是名称节点的热备份，其命名不恰当，它为名称节点组件执行一些内务处理功能（housekeeping functions）
        数据节点（DataNode）：
            把真正的数据块存放在本地硬盘上，组成保存在HDFS上的每个文件
        作业跟踪器（JobTracker）：
            主要组件之一，负责一个任务的整个执行过程，具体功能包括：
                调度各个子任务（Mapper任务和Reducer任务各自的子任务）到各自的计算节点运行
                时刻监督任务运行和计算节点的健康状况
                对失败的子任务重新调度执行
            也是使用Hadoop 1.x搭建大型计算集群系统的瓶颈所在
        任务跟踪器（TaskTracker）：
            运行在各个数据节点上，用来启动和管理各个Map/Reduce任务，与作业跟踪器进行通信
    
    Hadoop 1.x集群有两种类型的节点：主节点（master nodes）和从节点（slave nodes）
    主节点负责执行如下守护进程：
        名称节点进程
        辅助名称节点进程
        作业跟踪器进程
    从节点分布在整个集群上并执行如下守护进程：
        数据节点进程
        任务跟踪进程
    
    整个集群上，每种主节点守护进程只有一个运行实例，但其数据节点进程和任务跟踪器进程有多个运行实例
    规模较小或用于开发/测试的集群，三个主节点进程在一台服务器上；生产环境系统或规模较大的集群，三个主节点进程分别运行在不同的服务器上较好

    2.3.1Hadoop分布式文件系统
        即HDFS，用于支持大数据处理程序要处理的大文件，有一次写、多次读的特点，由以下几个守护进程协调运行来提供服务：
            名称节点进程
            辅助名称节点进程
            数据节点进程
        HDFS系统也是主从架构，运行名称节点进程的服务器为主节点，运行数据节点进程的服务器为从节点
        一般集群每个从节点都会运行一个数据节点进程，管理着挂载到这个数据节点上的存储设备
        HDFS系统提供一个统一的文件系统命名空间，用户像使用文件系统一样来存取集群节点上的数据
        名称节点进程负责管理存储在集群上的文件的元数据

        1.Hadoop文件的本质是块存储
            集群中文件的物理存储方式：每个文件被分隔为多个数据块，典型大小为64MB，也可配置为32MB或128MB
            文件块大小按照文件大小配置，若文件大小不是文件块大小的整数倍，空间不会浪费很多，只是最后一个文件块未被完全占满
            每个数据块存储在数据节点上，为防止节点故障，数据块有备份，备份默认配置为3
            具备机架感知功能的Hadoop系统把文件的一个数据块存放在本地机架上的一台计算节点上
            （假设Hadoop客户端运行在本地机架中的一台数据节点上，否则会随机选择一个机架）
            第二个备份存放在另外一个远程机架上的计算节点中，第三个备份存放在第二个数据块备份机架上的另一台计算节点中
            Hadoop系统借助一个单独配置的网络拓扑文件实现机架感知功能，该文件配置了机架到计算节点的域名系统（DNS）名称之间的映射
            该文件的路径配置在Hadoop配置文件中
                许多Hadoop系统会把文件备份因子降为2，如运行在EMC公司的Isilon硬件上的Hadoop系统
                原因是这套硬件系统使用了RAID5的技术，该技术本身内置了数据的冗余备份，从而可降低Hadoop系统的文件备份因子
                降低文件备份因子的一个好处就是提高系统的I/O性能（少写一个备份）

            为什么不把三个文件数据块备份分别存放在不同的机架上？这样可以增加数据冗余度，抵御机架故障的能力更强，还可增加机架的数据吞吐量
            但是，机架故障的概率远低于计算节点故障的概率，而把数据块备份到不同机架可导致Hadoop系统写性能大幅下降
            所以，折中方案就是把两个数据块备份存放在同一个远程机架上的不同计算节点中，以换取Hadoop系统写性能的提高

        2.文件元数据和名称节点
            当客户端向HDFS请求读取或存储一个文件时，需要知道要访问的数据节点是哪一个，知道之后可直接访问那个数据节点
            文件的元数据信息由名称节点维护，HDFS系统提供一个统一的文件系统命名空间，用户像使用文件系统一样存取集群节点上的数据
            HDFS把存储在目录的文件按一定的层级展示，目录是可嵌套的，所有文件和目录的元数据信息都由名称节点管理

            名称节点管理所有的文件操作，包括文件/目录的打开、关闭、重命名、移动等，数据节点负责存储实际文件数据
            当客户点请求或发送文件数据，其物理上不经过名称节点传输，客户端仅从名称节点获取文件元数据，后根据信息直接从数据节点获取数据块
            名称节点存储的一些元数据：
                文件/目录名称及相对于其父目录的位置
                文件和目录的所有权及权限
                各个数据块的文件名，所有数据块以文件形式存放在数据节点的本地文件系统的目录中，目录可被Hadoop系统管理员配置

            注意，名称节点不存储每个数据块的位置（数据节点的身份信息），数据节点的身份信息（DataNode identity）在集群启动时从每个数据节点获取
            名称节点维护的信息是，HDFS上的文件由哪些数据块（数据节点上每个数据块的文件名）组成

            元数据存储在名称节点的本地磁盘上，但为了快速访问，在集群操作时会把这些元信息加载到内存，同时也成为一个瓶颈，催生了Hadoop 2.x系统
            每个元数据信息大约占用200字节的RAM，假设一个1GB大小的文件，数据块大小为64MB，需要16X3（包括备份数量）=48个数据块的存储量
            假设由1000个文件，每个大小1MB，需要1000X3=3000个数据块的存储量（每个文件占用数据块1MB存储空间，多个文件不能存储在同一数据块中）
            如此元数据的数据量会大幅增长，导致名称节点更大的内存占用，这也解释了为什么Hadoop系统更适合存储大文件，不适合存储大量小文件

            名称节点服务器存放元数据的文件为fsimage
            Hadoop系统运行期间任何涉及元数据修改的操作都保存在内存中，并被持久存储到另一个edits文件
            辅助名称节点会周期性地把edits文件中的信息合并到fsimage文件
            保存在HDFS的实际文件数据并不会存放在fsimage和edits文件，实际数据存放在运行着数据节点守护进程的从节点的数据块中
            但如果名称节点保存的元数据丢失，会导致整个集群不可用
            数据节点守护进程周期性的发送心跳信息给名称节点，使得名称节点可以感知所有数据节点的健康状况，从而客户端的请求不会被发送到故障数据节点

        3.HDFS系统写文件的机制
            HDFS的写操作涉及文件的创建，客户端把文件写入到HDFS需要以下几步：
                1.客户端在联系名称节点前，会把文件数据流式地读入（streaming the file contents）到客户端本地文件系统的一个临时文件中
                2.当文件数据大小达到一个数据块大小时，客户端联系名称节点
                3.名称节点会在HDFS的层级结构中创建一个文件，然后把数据块的标识符和数据节点上的位置信息发给客户端
                    这个数据节点数据块信息列表里还包括其备份节点的数据块信息列表
                4.之后客户端会根据数据块信息把本地临时文件中的数据刷新（flush）到集群上的数据块中（只写入到第一个数据节点）
                    这样真实的文件数据就放在了集群数据节点本地文件存储系统中
                5.当文件被关闭时，名称节点会执行一个提交操作，使得该文件在集群中为可见状态，若在提交操作完成前名称节点挂掉，这个文件就丢失了
                步骤4中的刷新操作过程如下：
                    1.第一个数据节点以数据包（一般大小4KB）形式从客户端接收数据，这个数据包写入其本地存储时，会被传送到第二个数据节点
                    2.第二个数据节点开始把数据包写入本地磁盘时，这个数据包会被传送到第三个数据节点
                    3.最终这个包含文件数据的数据包写入第三个数据节点，这部分文件数据及其备份就以数据管道的方式存放到HDFS中
                    4.保存数据包成功后，其确认包（acknowledgment packet）会从保存该数据包的计算节点
                        通过数据管道返回给前一个保存该数据包的计算节点，最后第一个数据节点会发送确认包到客户端
                    5.当客户端接收到数据块保存成功的确认，数据块就被认为持久地存储到集群中的计算节点上，客户端会发送最终确认信息给名称节点
                    6.在数据管道中的任何数据节点发生故障，数据管道就会关闭，文件数据会被写入其他数据节点
                        名称节点感知到文件数据没有备份完成，会执行重新备份过程，把数据备份到状态良好的节点，以确保达到要求的文件备份水平
                    7.每个数据块有一个校验和，用来检测数据块完整性，这些校验和存放在HDFS另一个隐藏文件，当读取数据块时用来校验数据块完整性

        4.HDFS系统读文件的机制
            客户端从HDFS中读取文件步骤：
                1.客户端访问名称节点，名称节点返回组成文件的数据块列表及数据块位置（包括备份数据块位置）
                2.客户端直接访问数据节点获取数据块中的数据，如果数据节点出现故障就会访问存放备份数据块的数据节点
                3.读取数据块时会计算该数据块的校验和，并与写入文件时的校验和比较，若校验失败，则从其他数据节点获取备份数据块

        5.HDFS系统删除文件的机制
            步骤：
                1.名称节点仅重命名了文件路径，使其移动到了/trash目录，这个操作过程是链接到重命名文件路径的元数据的更新操作
                    该执行过程迅速，/trash目录的文件会保存一段预先确定的时间（当前设定为6小时且当前不可配置），这段时间内移动出来即可恢复
                2.当/trash目录的文件超过保存时间，名称节点会将该文件从HDFS命名空间中删除
                3.删除文件使得相关数据块被释放，HDFS随后会显示增加了一些空闲空间
            
            文件备份因子是可变的，可减小；通过一次心跳信息，文件备份因子变化信息就由名称节点发出，数据节点动态地从本地存储系统删除相应数据块
            名称节点可以动态维护文件的备份数量

        6.确保HDFS系统的可靠性
            Hadoop系统和HDFS系统都有很强的抗故障能力，以下两种情况会造成数据丢失：
                1.数据节点故障：
                    每个数据节点周期性地发送心跳信息到名称节点（默认3秒一次），若在预定时间段内没收到心跳信息，它就会认为数据节点有故障
                    名称节点就会主动对存储在故障数据节点的数据块重新备份，（从其他健康节点的备份数据块获取）转移到健康数据节点，确保备份数量不变
                2.位腐（bit rot）现象导致的数据损坏：
                    指电荷（在传输过程中）发生衰减导致数据丢失，在HDFS读取数据块操作过程中会进行数据校验和核对，这种情况的数据损坏会被发现
                    若校验失败，便认为数据块已损坏，会读取备份，然后名称节点重新备份，使得备份数量达到预设数量

    2.3.2辅助名称节点
        辅助名称节点不是用于进行故障切换的节点
        名称节点在内存中维护所有元数据，即最先从存放在本地文件系统中的fsimage文件将元数据加载到内存中
        元数据信息在内存中不断更新，这些数据操作记录被持久存储到另一个叫edits的本地文件
            fsimage文件并不实际存储各个数据块位置，这些信息是Hadoop系统在每个数据节点启动时，名称节点从每个数据节点获取并存放在内存中

        edits文件用来收集元数据变化，如果Hadoop系统重启，重启过程中edits文件的内容会与fsimage文件中的内容合并，这会拖慢重启时间
        辅助名称节点周期性地把edits文件中的内容与fsimage文件中的内容合并，步骤如下：
            1.辅助名称节点请求名称节点来结转（roll over）edits文件，确保新的更新保存到新的文件，新的文件叫做edits.new
            2.辅助名称节点向名称节点请求获取fsimage文件和edits文件
            3.辅助名称节点把edits文件和fsimage文件和并，生产一个新的fsimage文件
            4.名称节点从辅助名称节点接收到新生成的fsimage文件，并替代旧的fsimage文件
                同时将edits文件中的内容替换成步骤1创建的edit.new文件的内容
            5.更新fstime文件记录发送的检查点操作

        如果edits文件和fsimage文件数据损坏，存放在HDFS上的所有数据都会丢失；集群数据节点是安装了JBOD（不使用RAID技术的数组硬盘）的商用服务器
        而名称节点和辅助名称节点必须安装更为可靠的存储系统（基于RAID技术的存储系统），确保数据不丢失，且edits和fsimage文件必须定期备份
            fsimage：保存了最近的一次检查点的HDFS系统元数据的持久化状态信息
            edits：保存了最近的一次检查点之后到现在的HDFS系统元数据的状态变化信息
            fstime：保存了最近一次检查点的时间戳

    2.3.3任务跟踪器
        任务跟踪器（TaskTracker）守护进程在集群中每台计算节点中运行，接收Map、Reduce和Shuffle这些操作任务的请求
        每个任务跟踪器都会分配一定的槽位数（a set of slots），一般与计算节点上可用的CPU核数一致
        任务跟踪器接收到一个（来自作业跟踪器）的请求后，会启动一个任务（task），初始化一个新的JVM
        任务跟踪器分配一项任务取决于它的可用槽位（slots）数量（槽位数量=实际运行的任务数量）
        任务跟踪器负责向作业跟踪器（JobTracker）发送心跳消息，包括反馈任务跟踪器的运行状况、任务跟踪器当前可用槽位数量

    2.3.4作业跟踪器
        作业跟踪器（JobTracker）守护进程负责启动和监控MapReduce作业，详细步骤如下：
            1.作业跟踪器接收到了作业请求
            2.大多数MapReduce作业都需要一个或多个输入文件目录，任务跟踪器向名称节点发出请求，获得数据节点列表
                该列表上的数据节点存储了组成输入文件数据的数据块
            3.作业跟踪器为作业的执行做准备工作，任务跟踪器确定执行该作业需要的任务（Map任务和Reduce任务）数量
                作业跟踪器尽量把这些任务都调度到离数据块最近的位置上
            4.作业跟踪器把任务提交到每个任务跟踪器节点去执行，任务跟踪器节点监控任务执行情况
                任务跟踪器以预设的时间间隔发送心跳信息到作业跟踪器，若未收到则认为该任务跟踪器故障，任务会被调度到另一节点运行
            5.所有任务执行完毕，作业跟踪器会更新作业状态为成功，若任务反复失败达到一定数量（可通过Hadoop系统配置文件指定），就会宣布作业失败
            6.客户端会轮询作业跟踪器及时地获得作业运行状态
        作业跟踪器故障会导致Hadoop系统单点故障，若其挂掉，集群所有任务都无法正确运行
        同样由于仅有一个作业跟踪器节点运行，多任务同时运行的系统环境中，会增加该作业跟踪器节点的负载

2.4Hadoop 2.0
    MapReduce进行升级，即Hadoop 2.0，又被称为MapReduce 2.0（MR v2）或YARN
    MR v2是一套应用编程接口（API），兼容MR v1，根据MR v1接口编写的程序仅需重新编译即可
    其底层架构完全改变，Hadoop 1.x的作业调度器承担两个主要功能：
        资源管理（Resource management）
        作业调度/作业监控（Job scheduling/Job monitoring）
    YARN把这两个功能分为两个守护进程来分别承担，使得系统有一个全局的资源管理器以及每个程序有一个应用程序管理器（Application Master）
    注意，这里是程序（Application），而不是作业（Job）
    在Hadoop 2.x系统中，一个程序（application）可指传统概念上的单独的MapReduce作业
    也可指一些列作业组成的有向无环图（Directed Acyclic Graph，DAG），DAG是一个由许多节点相连构成的图，图中没有循环
    多个作业组成了有向无环图就意味着这些作业之间存在着层属关系（hierarchical relationship）
    YARN还使得Hadoop不仅仅局限于MapReduce
        如Apache Hive给Hadoop系统带来了SQL特性
        Apache PIG可让用户使用基于脚本的数据流方式处理数据
        HAMA这样的新框架使得Hadoop系统更适合迭代计算，在机器学习的应用场景中很有用
        来自Berkley的Spark/Shark框架是Hive和HAMA的结合，提供了低延时的SQL访问和一些内存计算能力

    对框架重新设计，使得基于海量数据批处理计算框架（不仅是MapReduce模型），基于HAMA的数据整体同步并行计算（BSP）框架
    基于Shark／Spark的内存缓存和计算框架都能运行在统一的Hadoop系统上，整个Hadoop系统对其提供一致的原生支持
    使得关于安全和资源管理的系统级策略能以一致的方式应用，所有系统都共享相同的底层HDFS
    YARN系统由以下几个部分组成：
        全局资源管理系统（Global Resource Manager）
        节点管理器（Node Manager）
        针对每种应用程序的应用程序管理器（Application-specific Application Master）
        调度器（Scheduler）
        容器（Container）

    一部分CPU内核和一部分内存构成了一个容器
    一个应用程序（application）运行在一组容器中
    应用程序管理器的一个实例会向全局资源管理器请求获取资源
    调度器会通过每个节点的节点管理器（Node Manager）来分配资源（容器）
    节点管理器会向全局资源管理器汇报每个容器的使用情况

    全局资源管理器和每个节点的节点管理器构成了新的MapReduce框架的管理系统，全局资源管理器全权负责系统资源的分配
    每种应用程序都有一个应用程序管理器（比如MapReduce是一种应用程序，每个MapReduce作业是MapReduce类型程序的一个实例）
    针对同一应用程序类型的所有应用程序，一个应用程序管理器实例被初始化，应用程序管理器实例（instance）向全局资源管理器协商获得容器运行作业
    全局资源管理器利用调度器（全局组件）与每个节点的节点管理器的沟通结果来分配资源，从系统角度看，应用程序管理器也运行在一个容器中
    整体上，我们在一群商用服务器上搭建了Hadoop集群，每台服务器称为一个节点

    2.4.1容器
        容器（Container）是YARN框架中的计算单元，是一个任务进行工作的单元子系统，相当于MapReduce v1中的一个任务（task）执行器
        一个节点可运行多个容器，一个容器只能运行在一个节点内，一个容器就是已分配的一组系统资源，目前支持两种类型的系统资源：
            中央处理器内核（CPU core）
            内存（单位为MB）
        用于系统资源的容器在某一节点上执行，所以隐含了“资源名称”的概念，就是容器所在机架和节点的名称
        请求一个容器时会向一个节点发出请求，容器使得程序可在某个节点上获得指定数量的CPU内核和一定的内存
        实际任何任务或程序（单个任务或多个任务组成的有向无环图）都运行在一个或多个容器中，在YARN框架中全权负责分配容器的组件叫节点管理器
    
    2.4.2节点管理器
        节点管理器（Node Manager）运行在集群的一个节点上，每个节点都运行一个自己的节点管理器
        作为一个从属服务（slave service）：它接受来自另一个称为资源管理器的组件的请求，然后分配容器给应用程序
        它还负责监控和汇报资源使用情况给资源管理器，双方一起协同工作，负责管理分配Hadoop系统资源
        资源管理器时全局组件，节点管理器作为各个节点的代理负责管理每个节点的健康情况，任务如下：
            1.接受来自资源管理器的请求，为作业的执行分配容器
            2.与资源管理器交换信息，确保集群稳定运行，资源管理器依靠各个节点管理器的汇报来跟踪集群的健康状况
                节点管理器作为代理任务来监控和管理本节点的健康状况
            3.管理每个已启动的容器的整个生命周期
            4.每个节点的日志管理
            5.运行各种YARN应用程序使用的辅助服务（auxiliary service），如Shuffle服务就是一个辅助服务
        
        当一个节点启动，会向资源管理器注册，告诉其有多少资源（最终可分配给容器使用的资源）可用
        节点管理器仅对抽象出来的容器进行管理，对单个应用程序或应用程序类型的情况一无所知，这部分由应用程序管理器负责
    
    2.4.3资源管理器
        资源管理器的核心是一个调度器：当多个应用程序竞争使用集群资源时，它负责资源的分配调度，确保集群资源的优化合理使用
        资源管理器有一个插件化的调度器，按照程序队列和集群的处理能力，为运行的多个应用程序分配集群资源，自带计算能力调度器和公平调度器
        一个任务的启动、配置及其资源的监控都由计算节点上的节点管理器（Node Manager）负责
        这种职责的分离使得资源管理器相比传统的作业调度器（JobScheduler）具备更好的系统扩展性
