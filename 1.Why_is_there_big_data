1.为什么会有大数据
2005年前后，数据处理需求增长速度快于计算资源处理能力的提升速度
更加紧急有效的解决办法就是数据的并行处理
Hadoop就是利用互相联网的多台计算机使用MapReduce（一种改进的单指令多数据流[SIMD]计算技术）并行地处理计算大量数据
1.1什么是大数据
    本书，大数据定义为无法被符合服务等级协议（service level agreement, SLA）
        的单台计算机处理或（有些时候）存储的任何数据集

1.2大数据技术背后的核心思想
    核心问题：可以很快地处理数据，但从持久性的存储设备中读取的速度受到限制，这是数据处理流程的关键瓶颈
    相对于读写本地节点存储设备上的数据，通过网络传输数据会更慢
    大数据处理方法的共同特征：
        数据分布在多个节点（网络I/O速度<<本地磁盘I/O速度）
        计算程序离数据更近（集群上的节点），而不是相反
        数据的处理尽量在本地完成（网络I/O速度<<本地磁盘I/O速度）
        使用可顺序读取磁盘I/O代替随机读取磁盘I/O（数据交换速度<<数据寻道时间）
    所有大数据计算处理模式都有的目的，使输入/输出（I/O）并行化，从而提高数据处理性能
    
    1.2.1把数据分发到多个节点
        把要处理的数据分布存放在多个计算节点，不是因为数据量有数十T之巨
        最终目的是为了让大量计算节点同时参与到数据的处理计算过程中
        好处：
            每个数据块会在多个节点上有多份拷贝（Hadoop默认是一个数据块有3份拷贝），使得系统具备容错性
            为了达到数据并行处理的目的，多个节点可以同时参与数据处理过程

    1.2.2把计算逻辑移动到数据附近
        J2EE中，三/四层架构思想主导。在三/四层编程模型中，数据通过网络集中，交由应用层处理。数据分散，程序集中
        大数据系统无法处理网络过载问题。应该把数据分布存放到各个计算节点，程序也要移动到数据附近
        除了程序，程序运行所依赖的函数库也要移动到数据处理节点
        大数据系统可以集中式地部署程序代码，后台在计算任务启动之前把程序移动到各个数据处理节点

    1.2.3计算节点进行本地数据处理
        大数据系统会把计算任务尽量调度到离数据最近的节点
        某些特定的处理任务需要跨节点获取数据
        计算结果最终要汇聚到一个计算节点（MapReduce框架的Reduce阶段或其他海量数据并行化处理编程模型的类似阶段）
            起码这一步是需要跨节点获取数据的

    1.2.4优选顺序读，次之随机读
        从磁盘读取数据：
            首先，寻道（seek）：磁盘头移动到所寻找的数据所在的磁盘位置，需要花费很多时间
            之后，传输（transfer）：数据被顺序地读取出来
        读取花费时间：寻道时间 X 寻道次数 + 传输单位数据的时间 X 数据量
        顺序读寻道次数1；随机读寻道次数n（磁盘上彼此不相邻的扇区数）
        大多数数据读取密集型的大数据编程模型都利用了这个特征，数据被顺序地从磁盘上读出，然后在内存中过滤数据
        关系型数据库管理系统（RDBMS）模型往往以随机读取数据为主

    1.2.5一个例子
        一般步骤：
            1.每个计算节点读取分发给自己的全部数据，在内存中过滤，避免磁盘的寻道时间
            2.各个计算节点在处理数据时，没发现一个新的类别，就为它建立一个新的分组，把数据加到对应的分组中
            3.所有节点完成本地数据的磁盘读取工作，分别计算后，会把各自的计算结果发送到特点的计算节点
                汇聚（assembler）节点，是在计算任务伊始由所有节点协商出来的
            4.汇聚节点会汇聚全部结果，比如把各组来自不同计算节点的数据相加
            5.汇聚节点按照组把最终结果排序，输出排序结果
        该过程演示了大数据处理系统的典型特征：关注与使系统吞吐量（单位时间内系统处理的数据量）最大化
        而不是处理结果延时（请求响应的快慢，这个是评价事务性系统好坏的关键指标，因为想尽快获得响应）
