3.初识Hadoop框架
3.1安装类型
    对多种平台上安装Hadoop系统有个几把了解是重要的，原因如下：
        1.要想对Hadoop程序进行单元测试，Hadoop系统需要安装在单机模式下，在Linux中相对简单，Windows中非常繁琐
        2.为了能模拟Hadoop程序在集群中的运行情况，Hadoop系统提供了伪分布式集群模式下的操作
    安装详见https://github.com/74581/hello-world/blob/master/hadoop/hadoop_install

    3.1.1单机模式
        单机模式（Stand-Alone Mode），最简单的安装类型模式，最适合调试
        该模式中，Hadoop系统所有程序运行在一个单独的JVM中，性能最差，在开发过程中最高效
    
    3.1.2伪分布式集群模式
        伪分布式集群模式（Pseudo-Distributed Cluster），Hadoop系统以伪分布式的方式运行在一个服务器节点中
        所有守护进程分别运行在不同的Java进程中，经常用来模拟一个集群环境
    
    3.1.3多节点集群安装模式
        多节点集群安装模式（Multinode Node Cluster Installation），Hadoop系统安装在若干机器组成的集群中
        从系统逻辑上看，其运行情况与伪分布式模式是一致的
    
    3.1.4基于Amazon EMR预安装模式
        使用亚马逊公司的EMR（Elastic MapReduce）服务，背后主要思想如下：
            1.用户使用公司S3服务加载数据，S3是一项简单的存储服务
                由AWS（Amazon Web Service）提供的一个分布式文件存储系统
                它通过Web Services接口提供存储服务，扮演了HDFS的角色
                通过配置，Hadoop系统可以把其当作分布式文件系统使用
            2.用户也可使用其S3服务加载应用程序函数库
            3.用户通过指定函数库和输入文件在S3上的位置就可启动一个EMR作业，还要指定在S3上的输出目录供作业执行完毕写入输出结果
            4.在亚马逊云上启动一个Hadoop集群，执行作业，结果输出到上步指定目录中
        默认操作中，集群会被自动关闭，不必继续支付费用，用户可自己设定自动终止选项
        可使用SSH（Secure Shell）客户端登陆集群任何一个计算节点，就能继续使用Hadoop系统集群的全部功能

3.2使用Cloudera虚拟机搭建开发环境
    略

3.3一个MapReduce程序的组成
    各组成部分：
        Java程序客户机（Client Java program）：
            一个Java程序，由集群的一个客户端节点（边缘节点）提交运行
            该客户端节点可访问Hadoop集群，经常（并不总是）由集群的一个数据节点充当
            该节点仅是集群的一台机器，并有权访问Hadoop
        自定义Mapper类（Custom Mapper class）：
            MapReduce程序中的这个Mapper类通常是一个用户自定义类
            若不是在伪集群模式下运行，这个类的实例会在远程任务节点上执行
            这些任务节点往往与用来提交作业程序的客户端节点不同
        自定义Reducer类（Custom Reducer class）：
            MapReduce程序中的这个Reducer类通常是一个用户自定义类
            若不是在伪集群模式下运行，这个类的实例会在远程任务节点上执行
            这些任务节点往往与用来提交作业程序的客户端节点不同
        客户端函数库（Client-side libraries）：
            不同于Hadoop系统的标准函数库，是在客户端运行期间使用的
            客户端需要使用的Hadoop系统的标准函数库已安装，使用通过Hadoop的Client命令（不同于客户端程序）配置到CLASSPATH中
            可在文件夹$HADOOP_HOME/bin/中找到，名为hadoop
            Hadoop命令用来执行客户端程序，会启动一个Hadoop作业
            这些函数库都被配置到了环境变量HADOOP_CLASSPATH中
        远程函数库（Remote libraries）：
            是用户自定义Mapper类和Reducer类所需要的，不包括Hadoop系统自带的函数库，自带函数库已经在每个数据节点配置好了
            如果Mapper类用到一个特殊的XML解析器，包含这个解析器的函数库就必须被传输到执行这个Mapper类实例的远程数据节点
        Java程序档案文件（Java Application Archive（JAR）files）：
            Java程序以JAR文件的形式打包，包括了客户端Java类，以及用户自定义Mapper类和Reducer类
            还包括了客户端Java类、Mapper类和Reducer类用到的其他自定义依赖类

3.4第一个Hadoop程序
    书中原开发环境：带有Maven插件的Eclipse
    首先创建一个空的Maven工程，添加所需依赖库，创建项目对象模型（Project Object Model，POM）
    现在由两套MapReduce API，旧API已经被废弃，但之前广泛使用
    
    3.4.1以本地模式运行程序的必要条件
        以本地模式运行Hadoop程序是非常重要的，可以对程序做单元测试以便快速进行开发工作
        要做的唯一工作是正确配置HADOOP_HOME环境变量，而且{HADOOP_HOME}/bin要包含在PATH变量中
        但是，在Windows环境中，Hadoop程序所需要应用的动态链接库（DLL）都要在本机配置好
