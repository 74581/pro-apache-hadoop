3.初识Hadoop框架
3.1安装类型
    对多种平台上安装Hadoop系统有个几把了解是重要的，原因如下：
        1.要想对Hadoop程序进行单元测试，Hadoop系统需要安装在单机模式下，在Linux中相对简单，Windows中非常繁琐
        2.为了能模拟Hadoop程序在集群中的运行情况，Hadoop系统提供了伪分布式集群模式下的操作
    安装详见https://github.com/74581/hello-world/blob/master/hadoop/hadoop_install

    3.1.1单机模式
        单机模式（Stand-Alone Mode），最简单的安装类型模式，最适合调试
        该模式中，Hadoop系统所有程序运行在一个单独的JVM中，性能最差，在开发过程中最高效
    
    3.1.2伪分布式集群模式
        伪分布式集群模式（Pseudo-Distributed Cluster），Hadoop系统以伪分布式的方式运行在一个服务器节点中
        所有守护进程分别运行在不同的Java进程中，经常用来模拟一个集群环境
    
    3.1.3多节点集群安装模式
        多节点集群安装模式（Multinode Node Cluster Installation），Hadoop系统安装在若干机器组成的集群中
        从系统逻辑上看，其运行情况与伪分布式模式是一致的
    
    3.1.4基于Amazon EMR预安装模式
        使用亚马逊公司的EMR（Elastic MapReduce）服务，背后主要思想如下：
            1.用户使用公司S3服务加载数据，S3是一项简单的存储服务
                由AWS（Amazon Web Service）提供的一个分布式文件存储系统
                它通过Web Services接口提供存储服务，扮演了HDFS的角色
                通过配置，Hadoop系统可以把其当作分布式文件系统使用
            2.用户也可使用其S3服务加载应用程序函数库
            3.用户通过指定函数库和输入文件在S3上的位置就可启动一个EMR作业，还要指定在S3上的输出目录供作业执行完毕写入输出结果
            4.在亚马逊云上启动一个Hadoop集群，执行作业，结果输出到上步指定目录中
        默认操作中，集群会被自动关闭，不必继续支付费用，用户可自己设定自动终止选项
        可使用SSH（Secure Shell）客户端登陆集群任何一个计算节点，就能继续使用Hadoop系统集群的全部功能

3.2使用Cloudera虚拟机搭建开发环境
    略

3.3一个MapReduce程序的组成
    各组成部分：
        Java程序客户机（Client Java program）：
            一个Java程序，由集群的一个客户端节点（边缘节点）提交运行
            该客户端节点可访问Hadoop集群，经常（并不总是）由集群的一个数据节点充当
            该节点仅是集群的一台机器，并有权访问Hadoop
        自定义Mapper类（Custom Mapper class）：
            MapReduce程序中的这个Mapper类通常是一个用户自定义类
            若不是在伪集群模式下运行，这个类的实例会在远程任务节点上执行
            这些任务节点往往与用来提交作业程序的客户端节点不同
        自定义Reducer类（Custom Reducer class）：
            MapReduce程序中的这个Reducer类通常是一个用户自定义类
            若不是在伪集群模式下运行，这个类的实例会在远程任务节点上执行
            这些任务节点往往与用来提交作业程序的客户端节点不同
        客户端函数库（Client-side libraries）：
            不同于Hadoop系统的标准函数库，是在客户端运行期间使用的
            客户端需要使用的Hadoop系统的标准函数库已安装，使用通过Hadoop的Client命令（不同于客户端程序）配置到CLASSPATH中
            可在文件夹$HADOOP_HOME/bin/中找到，名为hadoop
            Hadoop命令用来执行客户端程序，会启动一个Hadoop作业
            这些函数库都被配置到了环境变量HADOOP_CLASSPATH中
        远程函数库（Remote libraries）：
            是用户自定义Mapper类和Reducer类所需要的，不包括Hadoop系统自带的函数库，自带函数库已经在每个数据节点配置好了
            如果Mapper类用到一个特殊的XML解析器，包含这个解析器的函数库就必须被传输到执行这个Mapper类实例的远程数据节点
        Java程序档案文件（Java Application Archive（JAR）files）：
            Java程序以JAR文件的形式打包，包括了客户端Java类，以及用户自定义Mapper类和Reducer类
            还包括了客户端Java类、Mapper类和Reducer类用到的其他自定义依赖类

3.4第一个Hadoop程序
    书中原开发环境：带有Maven插件的Eclipse
    首先创建一个空的Maven工程，添加所需依赖库，创建项目对象模型（Project Object Model，POM）
    现在由两套MapReduce API，旧API已经被废弃，但之前广泛使用
    
    3.4.1以本地模式运行程序的必要条件
        以本地模式运行Hadoop程序是非常重要的，可以对程序做单元测试以便快速进行开发工作
        要做的唯一工作是正确配置HADOOP_HOME环境变量，而且{HADOOP_HOME}/bin要包含在PATH变量中
        但是，在Windows环境中，Hadoop程序所需要应用的动态链接库（DLL）都要在本机配置好
    
    3.4.2使用旧API编写的单词计数程序
        hadoop_text: WordCountOldAPI.java
        展示的是使用已经被废弃的旧API编写的单词计数WordCount程序，维护老代码时会碰到
        
        程序开始，Mapper函数从输入文件夹中读取数据块，一个文件的字节流会被转换成一个记录（键/值对格式）作为Mapper的输入
        键是当前行字节偏移量（LongWritable.class实例），值（Text.class实例）是从文件中读取的一行文本数据
        Mapper发送每行的单词和整数1；注意：Hadoop作业程序需要使用与Integer.class对应的系统自带的IntWritable.class类
        因为Hadoop系统底层I/O传输设计，Hadoop作业程序的Mappers和Reducers的输入和输出必须是Writable.class类型的实例
        
        紧接着是Hadoop系统的Shuffle阶段，所有键在Shuffle/Sort阶段被排序，然后发送给Reducer
        Reducer接受到是一个IntWritable.class类实例的迭代器，在Reducer中使用的是相同的IntWritable.class类实例
        当Reducer迭代地取出键对应地一系列值，相同的IntWritable.class类实例被复用
        内部运行中，Hadoop系统框架在其迭代器中使用values.next()之后，调用IntWritable.get方法

        最后结果被写入由FileOutputFormat.setOutputPath(conf, new Path(args[1]))指定的输出文件目录中
        Reducer会向输出文件中写入结果键和值的实例，输出文件中的键和值实例的默认分隔符是TAB
        可通过配置参数：mapreduce.textoutputformat.separator修改
        如：conf.set("mapreduce.textoutputformat.separator", ",")会把键/值间的分隔符变为“，”

        真实集群运行作业，配置多少Reducers实例运行，就会生成多少个结果文件
